{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246c12e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f639cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce14db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x7f9d7f8b5130> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f9d7f4494f0> root_client=<openai.OpenAI object at 0x7f9d8de19490> root_async_client=<openai.AsyncOpenAI object at 0x7f9d7f8b50a0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f90ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"what is generative ai ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249bbd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to a class of artificial intelligence systems that are designed to create new content. These systems learn patterns from existing data and use that knowledge to generate new and original outputs. Generative AI can produce a wide variety of content, including:\\n\\n1. **Text**: Examples include GPT-3 and ChatGPT, which can write essays, articles, and even poetry by generating human-like text.\\n\\n2. **Images**: Systems like DALL-E and Stable Diffusion can create new images from text descriptions, while Generative Adversarial Networks (GANs) can produce realistic-looking images.\\n\\n3. **Music**: AI models can compose new pieces of music in various genres.\\n\\n4. **Videos**: Some generative models can create video content, either by animating still images or generating entirely new sequences.\\n\\n5. **Code**: AI can assist in writing or completing software code, automating parts of the software development process.\\n\\nGenerative AI models are typically based on neural network architectures, such as transformer models for text or convolutional networks for image-related tasks. These models are trained on large datasets to capture the underlying structure and distribution of the data, enabling them to generate plausible and creative new instances within the learned domain.\\n\\nThe technology has numerous applications across industries, from content creation and design to virtual reality and personalized entertainment. However, it also raises ethical and practical concerns, particularly regarding the potential for misuse, intellectual property rights, and the challenge of ensuring quality and accuracy in generated outputs.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d55f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are and expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are and expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16bd5673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a comprehensive platform designed to enhance the development and management of applications using large language models (LLMs) and retrieval-augmented generation (RAG) techniques. It combines aspects of data performance monitoring, testing, evaluation, and user validation into one cohesive environment. Key features of LangSmith include tools for fine-tuning language model prompts, tracking the effectiveness of various LLM implementations, and detailed analytics to evaluate performance metrics. Its integration-friendly architecture allows engineers to seamlessly incorporate it into existing workflows to optimize application performance and ensure reliable outcomes during production.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\",\"Can you tell me about langSmith\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36db78d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28c8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b459069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform associated with LangChain, a popular framework for developing applications powered by large language models (LLMs). LangSmith provides tools designed to enhance the development and deployment of LLM-based applications. Its primary features include observability, testing, and evaluation tools, which help developers monitor, debug, and refine their applications effectively. LangSmith allows developers to track how their models perform in real-world scenarios, identify bottlenecks, and make data-driven improvements. By integrating these capabilities, LangSmith aids in optimizing the interaction with language models, ensuring robust application performance and user satisfaction.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\",\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e9a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466dffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

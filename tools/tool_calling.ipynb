{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28eaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Option A: Using the @tool decorator with a docstring for description\n",
    "@tool\n",
    "def calculate_percentage_marks(marks_obtained: int, marks_total: int) -> float:\n",
    "    \"\"\"Calculate Percentage using Marks Obtained and Total Marks\"\"\"\n",
    "    percentage = (marks_obtained * 100.0) / marks_total\n",
    "    return round(percentage, 2)\n",
    "\n",
    "# Option B: Using Pydantic for more structured argument schema\n",
    "class AddInput(BaseModel):\n",
    "    a: int = Field(description=\"First integer to add\")\n",
    "    b: int = Field(description=\"Second integer to add\")\n",
    "\n",
    "@tool(args_schema=AddInput)\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two integers together and returns the result.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "tools = [calculate_percentage_marks, add_numbers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b84128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41017d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI # Or other compatible model, e.g., ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Ensure you have the necessary API key set in your environment variables\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# Bind the tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 670 marks out of a total of 850 is 78.82%.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "# 1. Invoke the LLM with a query that requires a tool\n",
    "messages = [HumanMessage(content=\"What is the percentage of 670 marks out of a total of 850?\")]\n",
    "response = llm_with_tools.invoke(messages)\n",
    "# print(response.tool_calls) \n",
    "# Example output will show a tool call request, e.g., [{'id': '...', 'name': 'calculate_percentage_marks', 'args': {'marks_obtained': 670, 'marks_total': 850}}]\n",
    "tool_messages = []\n",
    "# 2. Manually execute the tool call(s)\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        # Find the correct tool function and execute it with arguments\n",
    "        # A simple way to map name to function is a dictionary\n",
    "        # print(tool_call)\n",
    "        tool_map = {tool.name: tool for tool in tools}\n",
    "        selected_tool = tool_map[tool_call[\"name\"]]\n",
    "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "        \n",
    "        # 3. Create a ToolMessage with the output and append to messages\n",
    "        tool_messages.append(ToolMessage(content=str(tool_output), tool_call_id=tool_call[\"id\"]))\n",
    "    \n",
    "# 4. Invoke the model again with the original prompt AND the tool output\n",
    "final_response = llm_with_tools.invoke([HumanMessage(content=\"What is the percentage of 670 marks out of a total of 850?\"),response]+tool_messages)\n",
    "print(final_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec26421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
